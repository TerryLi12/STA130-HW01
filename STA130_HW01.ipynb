{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For questions 1-7, here are my chat logs:\n",
    "https://chatgpt.com/share/66e3b221-4940-8002-8ddf-5be37ed90c2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebb70d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repository creation was done with the help of ChatGPT.\n",
    "\n",
    "#using the STA130 University of Toronto Course, how do I make a notebook for my STA130 repo on github\n",
    "ChatGPT said:\n",
    "ChatGPT\n",
    "Creating a notebook for your STA130 (or any course) repository on GitHub involves a few steps. Here's a guide to help you set up a Jupyter Notebook for your STA130 repo:\n",
    "\n",
    "1. Set Up Your Environment\n",
    "Install Jupyter Notebook: If you haven't already, you need to install Jupyter Notebook. You can do this via Anaconda or pip. For pip, use:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "pip install notebook\n",
    "Install Git: Ensure Git is installed on your computer. If it's not, download and install it from git-scm.com.\n",
    "\n",
    "2. Create a New GitHub Repository\n",
    "Log In to GitHub: Go to GitHub and log in to your account.\n",
    "\n",
    "Create a New Repository:\n",
    "\n",
    "Click on the + icon in the top right corner and select \"New repository.\"\n",
    "Fill in the repository name (e.g., STA130-Notebook), add a description, and choose visibility (public or private).\n",
    "Click \"Create repository.\"\n",
    "3. Clone Your Repository Locally\n",
    "Clone Repository: Open your terminal or command prompt and clone your repository:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "git clone https://github.com/your-username/STA130-Notebook.git\n",
    "Replace your-username and STA130-Notebook with your GitHub username and repository name.\n",
    "\n",
    "Navigate to Repository:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "cd STA130-Notebook\n",
    "4. Create a Jupyter Notebook\n",
    "Start Jupyter Notebook: Run the following command in your terminal:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "jupyter notebook\n",
    "This will open a new tab in your browser with the Jupyter Notebook interface.\n",
    "\n",
    "Create a New Notebook:\n",
    "\n",
    "In the Jupyter Notebook interface, click on \"New\" and select \"Python 3\" (or the relevant kernel for your project).\n",
    "Add Content to Your Notebook:\n",
    "\n",
    "You can now add code cells, markdown cells, and any other content relevant to your STA130 course. For instance, you might include Python code for statistical analysis, explanatory text, or visualizations.\n",
    "5. Save and Push Your Notebook to GitHub\n",
    "Save Notebook: In Jupyter Notebook, click on \"File\" > \"Save and Checkpoint\" to save your work.\n",
    "\n",
    "Add and Commit Changes:\n",
    "\n",
    "Return to your terminal and ensure you're in your repository directory.\n",
    "\n",
    "Add the notebook file to staging:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "git add your-notebook.ipynb\n",
    "Replace your-notebook.ipynb with the actual filename.\n",
    "\n",
    "Commit the changes:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "git commit -m \"Add initial notebook for STA130\"\n",
    "Push to GitHub:\n",
    "\n",
    "Push your changes to the GitHub repository:\n",
    "bash\n",
    "Copy code\n",
    "git push origin main\n",
    "If your repository uses master as the default branch, replace main with master.\n",
    "6. Verify on GitHub\n",
    "Check Repository: Go to your GitHub repository page and check that your notebook file has been uploaded correctly.\n",
    "Additional Tips\n",
    "Use JupyterLab: For a more advanced interface, consider using JupyterLab, which is an extension of Jupyter Notebook with additional features. You can install it using:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "pip install jupyterlab\n",
    "And start it with:\n",
    "\n",
    "bash\n",
    "Copy code\n",
    "jupyter lab\n",
    "Version Control for Notebooks: If you want to keep track of changes more effectively, consider using nbdime to handle diffs and merges of notebooks.\n",
    "\n",
    "README.md: Include a README.md file in your repository to explain the purpose of the notebook, how to use it, and any other relevant information.\n",
    "\n",
    "By following these steps, you'll have a Jupyter Notebook in your GitHub repository for your STA130 course. If you have any specific requirements or additional features you need, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f53465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "row_n           0\n",
       "id              1\n",
       "name            0\n",
       "gender          0\n",
       "species         0\n",
       "birthday        0\n",
       "personality     0\n",
       "song           11\n",
       "phrase          0\n",
       "full_id         0\n",
       "url             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1.\n",
    "\n",
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3ae2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 391\n",
      "Number of columns: 11\n",
      "Column names: ['row_n', 'id', 'name', 'gender', 'species', 'birthday', 'personality', 'song', 'phrase', 'full_id', 'url']\n"
     ]
    }
   ],
   "source": [
    "#Question 2.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv'\n",
    "villagers_data = pd.read_csv(url)\n",
    "\n",
    "# Get the number of rows and columns\n",
    "rows, columns = villagers_data.shape\n",
    "\n",
    "# Display the column names, number of rows, and number of columns\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")\n",
    "print(\"Column names:\", villagers_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1b05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2 cont.\n",
    "\n",
    "Observations: are the individual data points or records in a dataset. In this dataset, each row represents a character from Animal Crossing, with different attributes associated with each one.\n",
    "\n",
    "Variables: are the characteristics or attributes that are recorded for each observation. In this dataset, the variables are the columns, such as the name, species, gender, personality, and other characteristics of the characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cadb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>391.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>239.902813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>140.702672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>363.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>483.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_n\n",
       "count  391.000000\n",
       "mean   239.902813\n",
       "std    140.702672\n",
       "min      2.000000\n",
       "25%    117.500000\n",
       "50%    240.000000\n",
       "75%    363.500000\n",
       "max    483.000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 3.\n",
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "\n",
    "# Reading the dataset\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Get a summary of the numerical columns\n",
    "df.describe()\n",
    "_____________________________________________\n",
    "#Summary of code learnt:\n",
    "#df.describe shows the summary statistics for each coloumn of the dataset. (numeric coloumns only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918b93a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "cat          23\n",
       "rabbit       20\n",
       "frog         18\n",
       "squirrel     18\n",
       "duck         17\n",
       "dog          16\n",
       "cub          16\n",
       "pig          15\n",
       "bear         15\n",
       "mouse        15\n",
       "horse        15\n",
       "bird         13\n",
       "penguin      13\n",
       "sheep        13\n",
       "elephant     11\n",
       "wolf         11\n",
       "ostrich      10\n",
       "deer         10\n",
       "eagle         9\n",
       "gorilla       9\n",
       "chicken       9\n",
       "koala         9\n",
       "goat          8\n",
       "hamster       8\n",
       "kangaroo      8\n",
       "monkey        8\n",
       "anteater      7\n",
       "hippo         7\n",
       "tiger         7\n",
       "alligator     7\n",
       "lion          7\n",
       "bull          6\n",
       "rhino         6\n",
       "cow           4\n",
       "octopus       3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3 Cont.\n",
    "\n",
    "# Count the occurrences of each \"unique\" value in the 'species' column\n",
    "df['species'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7bda2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 4. (Using Titanic Dataset now)\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Check the shape of the dataset (number of rows and columns)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7e55c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare',\n",
       "       'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town',\n",
       "       'alive', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4 Cont.\n",
    "\n",
    "# Get a summary of the numeric columns\n",
    "df.describe()\n",
    "\n",
    "# Display all column names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b88233f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5.\n",
    "\n",
    "Attributes:\n",
    "An attribute in a pandas DataFrame (like df.shape) represents stored information or properties about the DataFrame. Attributes do not perform any actions or calculations; instead, they just give direct access to specific characteristics of the data, such as the number of rows and columns (in the case of df.shape). Attributes do not require parentheses because they don’t involve any computation—just accessing stored data.\n",
    "\n",
    "Methods:\n",
    "A method (like df.describe()) is an action or operation that you can perform on a DataFrame. Methods are essentially functions that are built into the DataFrame object to carry out specific tasks like summarizing data, calculating statistics, or modifying the DataFrame. Methods require parentheses because they may take additional arguments and need to be \"called\" to execute the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0903e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 6.\n",
    "\n",
    "count:\n",
    "This shows how many values in the column are not missing. If values are missing, they arent included in the count.\n",
    "Example: If a column has 100 rows but 10 are missing, the count will be 90.\n",
    "    \n",
    "mean:\n",
    "Its the average of the values in the column. Calculated by adding all the values together and dividing by how many there are (not counting any missing ones).\n",
    "Example: If you have ages 10, 20, and 30, the mean average is (10 + 20 + 30) / 3 = 20.\n",
    "    \n",
    "std (Standard Deviation):\n",
    "This shows how spread out the values are from the average. A low standard deviation means the numbers are close to the average, and a high standard deviation means they’re more spread out.\n",
    "Example: If everyone’s age is around 20, the standard deviation will be low. If there’s a wide range of ages (e.g., 10, 50, 70), the standard deviation will be higher.\n",
    "    \n",
    "min:\n",
    "This is the smallest value in the column.\n",
    "Example: If the ages are 10, 20, and 30, the minimum value is 10.\n",
    "    \n",
    "25%:\n",
    "This is the value below which 25% of the data falls. In other words, 25% of the values are smaller than or equal to this number.\n",
    "Example: If you sort the values, this is the point where 25% of them are below and 75% are above.\n",
    "    \n",
    "50% or Median):\n",
    "This is the middle value when all the values are sorted. Half of the values are smaller than this, and half are larger.\n",
    "Example: If the ages are 10, 20, and 30, the median is 20.\n",
    "    \n",
    "75%:\n",
    "What it means: This is the value below which 75% of the data falls. In other words, 75% of the values are smaller than or equal to this number.\n",
    "Example: If you sort the values, this is the point where 75% of them are below and 25% are above.\n",
    "    \n",
    "max:\n",
    "What it means: This is the largest value in the column.\n",
    "Example: If the ages are 10, 20, and 30, the maximum value is 30.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ed9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 7.\n",
    "\n",
    "1. We have a dataset with passenger data from the Titanic, and we are doing an analysis where every column is important (age, sex, fare, etc.). If only a few rows have missing values for one or two columns, we want to remove those rows entirely using df.dropna().\n",
    "    \n",
    "2. We are analyzing the Titanic dataset, but the column cabin has too many missing values and is not relevant to your analysis. Instead of dropping rows, which might cause us to lose too much data, we would want to remove the cabin column altogether.\n",
    "\n",
    "3. Using del df['col'] before df.dropna() makes sure that we are removing unnecessary columns with lots of missing values first. This is so that when we later use df.dropna(), we will be dropping rows based on the remaining columns that are more important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c955d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: (891, 15)\n",
      "\n",
      "Missing values per column before cleaning:\n",
      "survived         0\n",
      "pclass           0\n",
      "sex              0\n",
      "age            177\n",
      "sibsp            0\n",
      "parch            0\n",
      "fare             0\n",
      "embarked         2\n",
      "class            0\n",
      "who              0\n",
      "adult_male       0\n",
      "deck           688\n",
      "embark_town      2\n",
      "alive            0\n",
      "alone            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Q7 Cont.\n",
    "\n",
    "#4.\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the shape of the dataset before cleaning\n",
    "print(\"Before cleaning:\", df.shape)\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"\\nMissing values per column before cleaning:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21e10732",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 Cont.\n",
    "\n",
    "Identify Columns with Significant Missing Values:\n",
    "\n",
    "The 'deck' column has 688 out of 891 rows missing.\n",
    "The 'age' column has 177 missing values.\n",
    "The 'embarked' and 'embark_town' columns have 2 missing values each.\n",
    "\n",
    "\n",
    "Decide Which Columns to Remove:\n",
    "\n",
    "Delete 'deck' Column:\n",
    "With a high percentage of missing data and less important to survival analysis, we can remove this column.\n",
    "Retain 'age':\n",
    "Despite missing values, 'age' is important for analysis (e.g., survival rates by age group). We'll handle its missing values differently.\n",
    "Retain 'embarked' and 'embark_town':\n",
    "These columns are useful, and with only 2 missing values, we can opt to drop the specific rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea12b7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 Cont.\n",
    "\n",
    "# Delete the 'deck' column\n",
    "del df['deck']\n",
    "\n",
    "# Drop rows with missing values in 'embarked' and 'embark_town'\n",
    "df = df.dropna(subset=['embarked', 'embark_town'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "803edf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 Cont.\n",
    "\n",
    "#Since we cant input missing values, we will drop rows with missing 'age' values\n",
    "df = df.dropna(subset=['age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b358306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning: (712, 14)\n",
      "\n",
      "Missing values per column after cleaning:\n",
      "survived       0\n",
      "pclass         0\n",
      "sex            0\n",
      "age            0\n",
      "sibsp          0\n",
      "parch          0\n",
      "fare           0\n",
      "embarked       0\n",
      "class          0\n",
      "who            0\n",
      "adult_male     0\n",
      "embark_town    0\n",
      "alive          0\n",
      "alone          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Q7 Cont.\n",
    "\n",
    "# Display the shape of the dataset after cleaning\n",
    "print(\"After cleaning:\", df.shape)\n",
    "\n",
    "# Check for missing values in each column\n",
    "print(\"\\nMissing values per column after cleaning:\")\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b60265",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 Cont.\n",
    "\n",
    "Justification:\n",
    "    \n",
    "\n",
    "Deleted 'deck' Column:\n",
    "\n",
    "With over 77% missing data, retaining this column would result in dropping too many rows if we used df.dropna().\n",
    "Deleting it preserves more of the dataset for analysis.\n",
    "\n",
    "\n",
    "Dropped Rows with Missing 'embarked', 'embark_town', and 'age':\n",
    "\n",
    "These columns are important for understanding passenger demographics and survival factors.\n",
    "With minimal missing values in 'embarked' and 'embark_town', dropping those specific rows has a negligible impact.\n",
    "For 'age', although we lose more rows, it's crucial to have complete data for accurate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For question 8, I have used a new conversation with a chatbot. Here are its logs: \n",
    "    https://chatgpt.com/share/66e3b1f1-2b20-8002-8c6a-320ea7a2b730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5573c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked', 'class', 'who', 'adult_male', 'deck', 'embark_town', 'alive', 'alone']\n"
     ]
    }
   ],
   "source": [
    "#Question 8.\n",
    "\n",
    "#Part 1.\n",
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display column names\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de91a261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>261.0</td>\n",
       "      <td>27.915709</td>\n",
       "      <td>14.110146</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>453.0</td>\n",
       "      <td>30.726645</td>\n",
       "      <td>14.678201</td>\n",
       "      <td>0.42</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count       mean        std   min   25%   50%   75%   max\n",
       "sex                                                              \n",
       "female  261.0  27.915709  14.110146  0.75  18.0  27.0  37.0  63.0\n",
       "male    453.0  30.726645  14.678201  0.42  21.0  29.0  39.0  80.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8 Cont.\n",
    "\n",
    "# Group by 'sex' and describe 'age'\n",
    "age_stats = df.groupby(\"sex\")[\"age\"].describe()\n",
    "age_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b438dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8 Cont.\n",
    "\n",
    "The groupby method in pandas is a powerful tool for splitting data into groups based on some criteria. When combined with .describe(), it allows us to compute summary statistics for each group separately. In the Titanic dataset, grouping by gender and describing ages can show demographic differences between male and female passengers. Male passengers are slightly older on average, but the age distribution between male and female are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb6851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8 Cont.\n",
    "\n",
    "#Part 2.\n",
    "\n",
    "The counts in df.describe() and df.groupby(\"col1\")[\"col2\"].describe() capture fundamentally different aspects of the data:\n",
    "\n",
    "df.describe() Counts:\n",
    "\n",
    "Reflect the overall completeness of each column across the entire dataset.\n",
    "Useful for identifying columns with missing data.\n",
    "df.groupby(\"col1\")[\"col2\"].describe() Counts:\n",
    "\n",
    "Show the number of observations within each group for a specific variable.\n",
    "Crucial for comparing groups, as they reveal the sample size and data distribution across categories.\n",
    "Help assess whether groups are balanced or if there are significant disparities in data availability.\n",
    "In essence, while both methods provide counts that account for missing data, the counts in the groupby context serve a dual purpose:\n",
    "\n",
    "Indicating Missing Data within Groups:\n",
    "\n",
    "Highlight if missing data is unevenly distributed among groups.\n",
    "Providing Group Sizes:\n",
    "\n",
    "Essential for statistical analysis and ensuring that comparisons between groups are valid.\n",
    "Understanding this difference is important because it affects how we interpret the data and the conclusions we can draw from our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4970905",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8 Cont.\n",
    "\n",
    "#Part 3.\n",
    "\n",
    "A. Using the ChatBot was quicker and more straightforward for this error.\n",
    "ChatBot Assistance:\n",
    "\n",
    "- The ChatBot quickly identified that pandas was not imported.\n",
    "- Suggested adding `import pandas as pd` at the beginning.\n",
    "\n",
    "Google Search:\n",
    "\n",
    "- Found the same solution on Stack Overflow.\n",
    "- Took more time to read through posts.\n",
    "\n",
    "\n",
    "B. The ChatBot was more helpful in quickly identifying the specific issue.\n",
    "ChatBot Assistance:\n",
    "\n",
    "- Identified that the file might not exist at the given URL.\n",
    "- Suggested checking for typos in the filename.\n",
    "- Corrected the URL to use 'titanic.csv'.\n",
    "\n",
    "Google Search:\n",
    "\n",
    "- General information about 404 errors.\n",
    "- Less direct in identifying the typo.\n",
    "\n",
    "\n",
    "C. The ChatBot was more efficient in diagnosing and resolving the error.\n",
    "ChatBot Assistance:\n",
    "\n",
    "- Noted that variable names are case-sensitive.\n",
    "- Suggested changing `DF` to `df`.\n",
    "\n",
    "Google Search:\n",
    "\n",
    "- General advice about undefined variables.\n",
    "- Less specific to the case sensitivity issue.\n",
    "\n",
    "\n",
    "D. The ChatBot was faster and more precise in identifying the error.\n",
    "ChatBot Assistance:\n",
    "\n",
    "- Identified the missing closing parenthesis.\n",
    "- Suggested adding `)` to complete the function call.\n",
    "\n",
    "Google Search:\n",
    "\n",
    "- General information about the error.\n",
    "- Required manual code review to find the issue.\n",
    "\n",
    "\n",
    "E. ChatBot was more efficient in fixing typos in function names.\n",
    "ChatBot Assistance:\n",
    "\n",
    "- Corrected `group_by` to `groupby`.\n",
    "- Corrected `describle` to `describe`.\n",
    "\n",
    "Google Search:\n",
    "\n",
    "- Provided general solutions.\n",
    "- Required more effort to pinpoint typos.\n",
    "\n",
    "\n",
    "F.ChatBot was more helpful in quickly resolving the errors.\n",
    "ChatBot Assistance:\n",
    "\n",
    "- Noted that column names are case-sensitive.\n",
    "- Corrected `\"Sex\"` to `\"sex\"` and `\"Age\"` to `\"age\"`.\n",
    "\n",
    "Google Search:\n",
    "\n",
    "- Provided general information on `KeyError`.\n",
    "- Required more steps to identify case issues.\n",
    "\n",
    "\n",
    "G. ChatBot was more efficient in resolving the errors.\n",
    "ChatBot Assistance:\n",
    "\n",
    "- Explained that column names need to be in quotes.\n",
    "- Corrected the code to include quotes around 'sex' and 'age'.\n",
    "\n",
    "Google Search:\n",
    "\n",
    "- General explanations about undefined names.\n",
    "- Less direct in providing the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12361b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 9.\n",
    "\n",
    "Yes I have consulted with chatbots and fully reviewed the course-wiki to ensure that I have adequate information to succesfully attempt the homework with the goal of learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5181b04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
