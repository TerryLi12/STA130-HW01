{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba28956",
   "metadata": {},
   "source": [
    "**Summary of Discussions with STA130 Specialized Chabot provided by ChatBot**\n",
    "\n",
    "This conversation began with a discussion about the deliverables for a hypothetical replication of Fisher's tea experiment with STA130 students. The initial focus was on understanding the core elements of hypothesis testing, including:\n",
    "●\n",
    "Formal and informal statements of the null hypothesis ($H_0$). [no source]\n",
    "●\n",
    "The alternative hypothesis ($H_A$). [no source]\n",
    "●\n",
    "The distinction between the population, sample, parameter of interest, and observed test statistic. [no source]\n",
    "The conversation then moved toward outlining a potential quantitative analysis using a simulation-based approach to estimate a p-value and evaluate the validity of $H_0$. This involved steps like:\n",
    "●\n",
    "Simulating the experiment under the assumption of $H_0$ using random number generation. [no source]\n",
    "●\n",
    "Calculating the test statistic for each simulated sample. [no source]\n",
    "●\n",
    "Constructing a sampling distribution from the simulated test statistics. [no source]\n",
    "●\n",
    "Determining the p-value by comparing the observed test statistic to the sampling distribution. [no source]\n",
    "The importance of explaining the purpose of the chosen methodology was also highlighted, emphasizing the need to:\n",
    "●\n",
    "Assess the plausibility of the null hypothesis. [no source]\n",
    "●\n",
    "Quantify the evidence against $H_0$. [no source]\n",
    "●\n",
    "Guide decision-making based on the p-value and potential errors. [no source]\n",
    "The conversation then shifted to address the nuances of applying Fisher's experiment to STA130 students, acknowledging the differences in population and sample size compared to the original experiment. This led to a more detailed discussion of:\n",
    "●\n",
    "The specific formal and informal null hypotheses for the STA130 student context. [no source]\n",
    "●\n",
    "The consideration of both a formal hypothesis testing approach using p-values and a potential confidence interval approach. [no source]\n",
    "The conversation concluded by outlining a structured report template, emphasizing the importance of:\n",
    "●\n",
    "Clearly documenting the code, methodology, and findings. [no source]\n",
    "●\n",
    "Using np.random.seed() for reproducibility in the simulation. [no source]\n",
    "●\n",
    "Providing a comprehensive conclusion regarding the null hypothesis based on the strength of evidence. [no source]\n",
    "Throughout the conversation, there was an emphasis on the probabilistic nature of hypothesis testing, particularly when using simulation, and the need to avoid definitive claims of proof or disproof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4b88e5",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "The key to statistically examining an idea is that it must be measurable and quantifiable. For example, \"people are happier on sunny days\" can be tested by measuring happiness and correlating it with weather data, while subjective ideas like \"blue is the most beautiful color\" cannot be statistically tested.\n",
    "\n",
    "A good null hypothesis is specific, testable, and falsifiable. It defines a population parameter and proposes a scenario of \"no effect,\" such as \"there is no difference in average height between men and women.\" In hypothesis testing, the null hypothesis is assumed true until evidence suggests otherwise. The process aims to find evidence against the null hypothesis, leading to its rejection if sufficient evidence exists. For example, testing a new fertilizer's effectiveness would involve a null hypothesis stating it has no effect on plant growth and an alternative hypothesis suggesting it does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a9f1d",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "In hypothesis testing, the results focus on population parameters rather than sample statistics. The population is the entire group of interest, while a sample is a smaller, representative subset. Each data point in the sample is denoted as 𝑥𝑖, and the sample mean, 𝑥bar, represents the average of these points. The population mean, 𝜇, is what we're ultimately interested in estimating, though it’s often unknown. Instead, we hypothesize a value for this mean, 𝜇0.\n",
    "\n",
    "Hypothesis testing uses sample data to infer if the hypothesized population mean, 𝜇0, is plausible. While calculations use 𝑥bar, conclusions are made about 𝜇, applying the test results to the entire population, not just the sample. Thus, the test’s outcome informs us about the population mean, guided by the sample as a representation of the broader group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7016417f",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "\n",
    "When calculating a p-value, we start by assuming the null hypothesis is true. This means we imagine a scenario where there is no effect or no difference, as proposed by the null hypothesis. By doing this, we establish a baseline or \"default\" world where nothing unusual is happening.\n",
    "\n",
    "Then, we look at our actual data and calculate the p-value to determine the probability of observing something as extreme as, or more extreme than, our sample results if this default world were real. If the p-value is very low, it suggests that such an outcome is unlikely to occur by chance in a world where the null hypothesis is true. This gives us reason to question the null hypothesis and consider the possibility that there might be an effect or difference after all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f6a01",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "\n",
    "A smaller p-value makes the null hypothesis seem more doubtful because it indicates that the observed data is very unlikely under the assumption that the null hypothesis is true. When we calculate a p-value, we start by imagining that the null hypothesis is correct and then determine the likelihood of seeing data as extreme as ours within this context.\n",
    "\n",
    "If the p-value is small, it means that our sample data is in the far tails of the sampling distribution under the null hypothesis—essentially, an improbable outcome in this imagined world. This suggests that the null hypothesis might not be an accurate reflection of reality. In other words, the smaller the p-value, the more it appears that the null hypothesis is not compatible with our data.\n",
    "\n",
    "A small p-value is considered strong evidence against the null hypothesis. When it falls below a certain threshold (often 0.05), we reject the null hypothesis, concluding that the observed results are unlikely to occur by random chance alone if the null hypothesis were true. So, while a small p-value doesn’t outright prove the null hypothesis is false, it makes it increasingly implausible, casting more doubt on its validity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8ad556",
   "metadata": {},
   "source": [
    "**Question 5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109c8b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00072"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulation parameters\n",
    "total_couples = 124  # Total number of couples\n",
    "right_tilts_observed = 80  # Observed right tilts\n",
    "probability_right_tilt = 0.5  # Null hypothesis probability of tilting right\n",
    "num_simulations = 100000  # Number of simulations for accuracy\n",
    "\n",
    "# Run the simulation: Number of right tilts for each simulated set of 124 couples\n",
    "simulated_tilts = np.random.binomial(total_couples, probability_right_tilt, num_simulations)\n",
    "\n",
    "# Calculate the p-value: probability of observing at least 80 right tilts under the null hypothesis\n",
    "p_value = np.mean(simulated_tilts >= right_tilts_observed)\n",
    "p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfc15ea",
   "metadata": {},
   "source": [
    "**Question 6**\n",
    "\n",
    "The concept of p-values is often misunderstood as providing proof of a hypothesis. However, a smaller p-value does not definitively prove that the null hypothesis is false; rather, it indicates that the observed data is less likely to have occurred under the null hypothesis, providing evidence against it. This does not equate to absolute proof, similar to how a p-value cannot definitively prove Fido's guilt or innocence.\n",
    "\n",
    "A smaller p-value suggests that the null hypothesis is questionable, while a larger one suggests that the evidence is consistent with it. Nonetheless, no specific p-value can confirm or disprove a hypothesis definitively. Instead, hypothesis testing involves evaluating evidence based on a predetermined significance level (often 0.05). If the p-value is below this level, we reject the null hypothesis, but this rejection does not mean absolute proof.\n",
    "\n",
    "Key points:\n",
    "\n",
    "P-values provide evidence, not proof, against the null hypothesis.\n",
    "Smaller p-values indicate stronger evidence against the null hypothesis.\n",
    "P-values do not definitively prove hypotheses.\n",
    "Decision-making relies on a significance level, not absolute certainty.\n",
    "The \"Vaccine Data Analysis Assignment\" (Week 4, Question 8) exemplifies this. In that case, bootstrapped confidence intervals and p-values suggested vaccine effectiveness, but did not definitively prove it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7e8f8",
   "metadata": {},
   "source": [
    "**Question 7**\n",
    "\n",
    "One-tailed and two-tailed hypothesis tests are approaches used in hypothesis testing to examine the direction and nature of an effect.\n",
    "\n",
    "Key Elements of Hypothesis Testing:\n",
    " - Null Hypothesis ($H_0$): Represents \"no effect\" or \"no difference.\"\n",
    " - Alternative Hypothesis ($H_A$): Suggests a specific effect or difference.\n",
    " - P-value: The probability of observing results as extreme as those in the data if the null hypothesis is true.\n",
    " \n",
    "Two-Tailed Tests:\n",
    " - A two-tailed test looks for any difference from the null hypothesis, in either direction.\n",
    " - In the context of the \"Vaccine Data Analysis Assignment,\" a two-tailed test would assess both potential improvements and worsening of health due to the vaccine.\n",
    " \n",
    "One-Tailed Tests:\n",
    " - A one-tailed test looks for a difference in a specific direction, based on a strong prior expectation.\n",
    " - For example, if the hypothesis is that the vaccine improves health, a one-tailed test would only consider data showing improvement.\n",
    " - The p-value is generally smaller in a one-tailed test because it focuses on one side of the distribution, which makes it easier to reject the null hypothesis in that specific direction.\n",
    " \n",
    "Modifying and Interpreting Tests:\n",
    " - To modify for a one-tailed test, adjust the p-value calculation to only include the tail that supports the alternative hypothesis.\n",
    " - Interpret one-tailed tests with caution: deciding on a one-tailed test must be done before examining the data to avoid biased conclusions.\n",
    " \n",
    "Choosing one- versus two-tailed tests before data analysis is essential to maintain objectivity, much like setting a significance level prior to analysis. This helps ensure the validity of statistical inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf9e894",
   "metadata": {},
   "source": [
    "**Question 8**\n",
    "\n",
    "**Problem Introduction**:\n",
    "\n",
    "This report analyzes a tea-tasting experiment inspired by Ronald Fisher's famous test with Dr. Muriel Bristol. In Fisher's experiment, Dr. Bristol claimed she could distinguish between tea with milk poured first versus tea poured before the milk. Fisher tested this claim using eight cups, four with milk first and four with tea first, and Dr. Bristol successfully identified each correctly.\n",
    "\n",
    "In this adaptation, we conducted a similar experiment with 80 STA130 students, where each student was given a single cup and asked to identify whether milk or tea was poured first. Out of the 80 students, 49 correctly identified the order. The purpose of this report is to analyze whether the observed result is significantly different from random guessing.\n",
    "\n",
    " - Relationship Between the Experiments:\n",
    " \n",
    "    In contrast to the personalized nature of Dr. Bristol's experiment, where an individual's specific sensory ability was tested, our experiment considers a larger and more abstract concept: whether an average student can distinguish between the pouring orders. The increased sample size and different population imply we are not testing a single individual's sensory ability but rather the general detectability of the pour order among a broader population.\n",
    "\n",
    " - Hypothesis Statement\n",
    "     \n",
    "    Null Hypothesis ($H_0$): The students are guessing, with no real ability to detect the difference. Thus, the probability of correctly identifying the order is 0.5.\n",
    "    Alternative Hypothesis ($H_A$): The students can detect the difference better than chance, with a probability of correctly identifying greater than 0.5.\n",
    "\n",
    "In everyday terms: If the null hypothesis is true, students are merely guessing and should be correct about half the time. If we find that significantly more than half guessed correctly, we have evidence that they might be able to taste the difference.\n",
    "                \n",
    "**Quantitative Analysis**\n",
    "\n",
    "Observed Test Statistic: Out of 80 students, 49 correctly identified the pouring order, resulting in an observed proportion of \n",
    "49/80 = 0.6125\n",
    "\n",
    "Significance Level: We will use a standard significance level of 0.05.\n",
    "\n",
    "p-value Estimation:\n",
    "To assess the probability of obtaining 49 or more correct answers under the null hypothesis, we can use a binomial test, as it directly applies here. Assuming a binomial distribution with parameters \n",
    "𝑛\n",
    "=\n",
    "80\n",
    "n=80 and \n",
    "𝑝\n",
    "=\n",
    "0.5\n",
    "p=0.5, we calculate the p-value for observing 49 or more correct answers.\n",
    "\n",
    " - Methodology and Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e92be14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.028332213172560572\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom\n",
    "\n",
    "# Setting a random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n = 80  # number of trials\n",
    "p = 0.5  # probability under null hypothesis\n",
    "\n",
    "# Observed statistic\n",
    "k = 49  # observed number of successes\n",
    "\n",
    "# Binomial test for p-value\n",
    "p_value = binom.sf(k - 1, n, p)  # p-value for observing at least 49 successes\n",
    "print(\"P-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d772a7f",
   "metadata": {},
   "source": [
    "**Findings and Discussions**\n",
    "\n",
    "The computed p-value represents the probability of obtaining 49 or more correct identifications if students are simply guessing. If this p-value is below our significance level (0.05), we would reject the null hypothesis, suggesting evidence that students can distinguish the pouring order.\n",
    "Given that 49 out of 80 is more than expected under random guessing (which would be around 40), a sufficiently low p-value would imply that students are not merely guessing.\n",
    "\n",
    "*Conclusion*\n",
    "\n",
    "Assuming the p-value is less than 0.05, we would reject the null hypothesis, indicating that students likely possess some ability to discern whether milk or tea was poured first. However, if the p-value is greater than 0.05, we fail to reject the null hypothesis, implying no significant evidence to suggest students can distinguish between the two pour orders.\n",
    "\n",
    "While the results of this analysis provide insights, they are context-specific and apply to the broader population of students rather than a unique sensory ability as tested in Fisher’s original experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965cdd29",
   "metadata": {},
   "source": [
    "**Question 9**\n",
    "\n",
    "ofc :|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffd597a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
